- [1、环境安装](#1环境安装)
- [2、Hadoop安装](#2hadoop安装)
- [3、集群安装](#3集群安装)
  - [3.1、前置说明](#31前置说明)
  - [3.2、前置准备](#32前置准备)
  - [3.4、配置集群](#34配置集群)
  - [3.5、启动集群](#35启动集群)
  - [3.6、配置历史任务](#36配置历史任务)
  - [3.7、配置日志聚集](#37配置日志聚集)
- [4、常用命令](#4常用命令)
- [5、常用端口号和时间同步](#5常用端口号和时间同步)
  - [5.1、常用端口号说明](#51常用端口号说明)
  - [5.2、时间同步](#52时间同步)
    - [5.2.1、说明](#521说明)
    - [5.2.2、配置](#522配置)
- [6、常见错误及解决方案](#6常见错误及解决方案)
# 1、环境安装

* linux最小需安装工具

  ```shell
  sudo yum install -y net-tools
  
  sudo yum install -y vim
  ```

* 关闭防火墙

  ```shell
  sudo systemctl stop firewalld
  sudo systemctl disable firewalld.service
  sudo systemctl status firewalld
  ```

  > 在企业中的服务器防火墙是开启的，内网访问也只会暴露指定端口。

* 创建操作用户

  ```shell
  useradd hp
  passwd hp
  
  # 简单密码设置
  echo 密码 | passwd --stdin 用户名
  ```

  > 方便后续学习的操作，给用户配置root权限。之后的所有操作都使用新创建的用户。
  >
  > ```shell
  > vim /etc/sudoers
  > 
  > root    ALL=(ALL)       ALL
  > 
  > ## Allows members of the 'sys' group to run networking, software, 
  > ## service management apps and more.
  > # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS
  > 
  > ## Allows people in group wheel to run all commands
  > %wheel  ALL=(ALL)       ALL
  > hp     ALL=(ALL)       NOPASSWD:ALL
  > ```
  >
  > 注意：新增的内容要放到 %wheel 后面。

* 创建工作目录，用于存储后续学习的各种文件

  ```shell
  sudo mkdir /opt/module
  sudo mkdir /opt/software
  
  # 指定文件夹的所有者和所属组
  sudo chown hp:hp /opt/module
  sudo chown hp:hp /opt/software
  ```

* 卸载自带的jdk

  ```shell
  rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
  ```

  > 注意：如果linux是最小安装可执行可不执行。

* 安装jdk

  1. 将jdk压缩包上传至工作目录（/opt/software）并进行解压。

     ```shell
     # 解压至 /opt/module/ 目录下
     tar -zxvf /opt/software/jdk-8u351-linux-x64.tar.gz -C /opt/module/
     ```

  2. 配置jdk环境变量

     ```shell
     # 新建用于hadoop相关环境变量的文件
     sudo vim /etc/profile.d/hp_env.sh
     
     # 添加以下内容,保存并退出。注意：jdk的目录需要根据自身进行修改
     #JAVA_HOME
     export JAVA_HOME=/opt/module/jdk1.8.0_351
     export PATH=$PATH:$JAVA_HOME/bin
     
     # 刷新环境变量
     source /etc/profile
     
     # 验证
     java -version
     ```

# 2、Hadoop安装

* 下载地址：https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/

1. 将安装包上传至工作目录（/opt/software/）并进行解压。

   ```shell
   # 解压至 /opt/module/ 目录下
   tar -zxvf /opt/software/hadoop-3.1.3.tar.gz -C /opt/module/
   ```

2. 配置hadoop环境变量

   ```shell
   sudo vim /etc/profile.d/hp_env.sh
   
   # 添加以下内容,保存并退出。注意：hadoop的目录需要根据自身进行修改
   # HADOOP_HOME
   export HADOOP_HOME=/opt/module/hadoop-3.1.3
   export PATH=$PATH:$HADOOP_HOME/bin
   export PATH=$PATH:$HADOOP_HOME/sbin
   
   # 刷新环境变量
   source /etc/profile
   
   # 验证
   hadoop version
   ```

# 3、集群安装

## 3.1、前置说明

* 建议准备三个及以上节点。安装jdk和hadoop，请参考前面章节的环境安装和hadoop安装。

* 修改ip、主机名、hosts

  ```shell
  # 修改ip目录
  cd /etc/sysconfig/network-scripts
  vi ifcfg-ens33
  
  # 修改主机名
  vi /etc/hostname
  
  # 修改hosts
  vi /etc/hosts
  ```

* 规划

  |      | hp-node1           | hp-node2                     | hp-node3                    |
  | ---- | ------------------ | ---------------------------- | --------------------------- |
  | HDFS | NameNode、DataName | DataName                     | SecondaryNameNode、DataName |
  | YARN | NodeManager        | ResourceManager、NodeManager | NodeManager                 |

  > * NameNode和SecondaryNameNode不要安装在同一台服务器。
  >
  > * ResourceManager也很消耗内存，不要与NameNode、SecondaryNameNode配置在同一台机器上。

* 默认配置文件说明

  | 文件名             | 默认位置                                                  |
  | ------------------ | --------------------------------------------------------- |
  | core-default.xml   | hadoop-common-3.1.3.jar/core-default.xml                  |
  | hdfs-default.xml   | hadoop-hdfs-3.1.3.jar/hdfs-default.xml                    |
  | yarn-default.xml   | hadoop-yarn-common-3.1.3.jar/yarn-default.xml             |
  | mapred-default.xml | hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml |

* 自定义配置文件

  core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在**$HADOOP_HOME/etc/hadoop**这个路径上，用户可以根据项目需求重新进行修改配置。

## 3.2、前置准备

* 编写工具脚本

  ```shell
   # 在用户家目录下创建用于存储脚本的目录
  mkdir -p ~/bin/
   
  cd ~/bin
  vim xsync
  ```

  ```shell
  #!/bin/bash
  
  #1. 判断参数个数
  if [ $# -lt 1 ]
  then
      echo Not Enough Arguement!
      exit;
  fi
  
  #2. 遍历集群所有机器
  for host in hp-node1 hp-node2 hp-node3
  do
      echo ====================  $host  ====================
      #3. 遍历所有目录，挨个发送
  
      for file in $@
      do
          #4. 判断文件是否存在
          if [ -e $file ]
              then
                  #5. 获取父目录
                  pdir=$(cd -P $(dirname $file); pwd)
  
                  #6. 获取当前文件的名称
                  fname=$(basename $file)
                  ssh $host "mkdir -p $pdir"
                  rsync -av $pdir/$fname $host:$pdir
              else
                  echo $file does not exists!
          fi
      done
  done
  ```

  ```shell
  # 添加执行权限
  chmod +x xsync
  
  # 配置环境变量,方便使用
  sudo vim /etc/profile.d/hp_env.sh
  
  # 添加以下内容 XSYNC
  export PATH=$PATH:/home/hp/bin
  
  # 刷新环境变量
  source /etc/profile
  ```

  ```shell
  # 将xsync拷贝到其它机器
  xsync /home/hp/bin/xsync
  
  # 将环境变量hp_env.sh拷贝到其它机器
  sudo /home/hp/bin/xsync  /etc/profile.d/hp_env.sh
  
  # 所有机器刷新环境变量
  source /etc/profile
  ```

  > 注意：如果使用sudo，那么xsync需全路径。

* 配置ssh免密（生产环境下不建议配置）

  1. 生产秘钥（公钥和私钥）

     ```shell
     ll ~/.ssh/id_*.pub
     
     ssh-keygen -t rsa
     ```

  2. 将公钥拷贝到其它机器

     ```sh
     ssh-copy-id hp-node1
     ssh-copy-id hp-node2
     ssh-copy-id hp-node3
     ```

## 3.4、配置集群

* 自定义配置文件

  ```shell
  mkdir -p $HADOOP_HOME/etc/hadoop
  ```

* 核心配置文件：core-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/core-site.xml
  ```

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  
  <configuration>
      <!-- 指定NameNode的地址 -->
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://hp-node1:8020</value>
      </property>
  
      <!-- 指定hadoop数据的存储目录 -->
      <property>
          <name>hadoop.tmp.dir</name>
          <value>/opt/module/hadoop-3.1.3/data</value>
      </property>
  
      <!-- 配置HDFS网页登录使用的静态用户为hp -->
      <property>
          <name>hadoop.http.staticuser.user</name>
          <value>hp</value>
      </property>
  </configuration>
  ```

* HDFS配置文件：hdfs-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
  ```

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  
  <configuration>
  	<!-- NameNode web 端访问地址-->
  	<property>
          <name>dfs.namenode.http-address</name>
          <value>hp-node1:9870</value>
      </property>
  	<!-- SecondaryNameNode web端访问地址-->
      <property>
          <name>dfs.namenode.secondary.http-address</name>
          <value>hp-node3:9868</value>
      </property>
  </configuration>
  ```

* YARN配置文件：yarn-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/yarn-site.xml
  ```

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  
  <configuration>
      <!-- 指定MR走shuffle -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>
  
      <!-- 指定 ResourceManager 地址-->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hp-node2</value>
      </property>
  
      <!-- 环境变量的继承 -->
      <property>
          <name>yarn.nodemanager.env-whitelist</name>
          <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
      </property>
  </configuration>
  ```

* MapReduce配置文件：mapred-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/mapred-site.xml
  ```

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  
  <configuration>
  	<!-- 指定 MapReduce 程序运行在Yarn上 -->
      <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
  </configuration>
  ```

* 将所有配置文件分发到其它机器上

  ```shell
  xsync $HADOOP_HOME/etc/hadoop/core-site.xml
  xsync $HADOOP_HOME/etc/hadoop/hdfs-site.xml
  xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml
  xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml
  
  # 查看分发情况
  cat $HADOOP_HOME/etc/hadoop/core-site.xml
  cat $HADOOP_HOME/etc/hadoop/hdfs-site.xml
  cat $HADOOP_HOME/etc/hadoop/yarn-site.xml
  cat $HADOOP_HOME/etc/hadoop/mapred-site.xml
  ```

## 3.5、启动集群

* 配置workers

  ```shell
  vim $HADOOP_HOME/etc/hadoop/workers
  
  # 添加以下内容
  hp-node1
  hp-node2
  hp-node3
  
  # 将文件分发到其它节点上
  xsync $HADOOP_HOME/etc/hadoop/workers
  ```

  > 注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。

* 启动集群

  * 如果集群是首次启动则需要格式化NameNode（在hp-node1节点上）。

    ```shell
    # hp-node1
    hdfs namenode -format
    ```

    > 注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止NameNode和DataNode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。

  * 启动HDFS

    ```shell
    # hp-node1
    start-dfs.sh
    ```

  * 启动YARN

    ```shell
    # hp-node2
    start-yarn.sh
    ```

* web端（浏览器）查看HDFS

  http://hp-node1:9870

  > 主机名（hp-node1）可替换成ip地址。

* web端（浏览器）查看YARN

  http://hp-node2:8088

## 3.6、配置历史任务

​	为了方便查看历史任务的运行情况，建议配置一下历史任务服务器。

* 修改配置文件：mapred-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/mapred-site.xml
  ```

  ```xml
  <!-- 添加以下内容 -->
  
  <!-- 历史服务器端地址 -->
  <property>
      <name>mapreduce.jobhistory.address</name>
      <value>hp-node1:10020</value>
  </property>
  
  <!-- 历史服务器web端地址 -->
  <property>
      <name>mapreduce.jobhistory.webapp.address</name>
      <value>hp-node1:19888</value>
  </property>
  ```

* 配置文件分发到其它节点并启动

  ```shell
  # 分发到其它节点
  xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml
  
  # 在hp-node1节点启动
  cd $HADOOP_HOME/etc/hadoop/
  mapred --daemon start historyserver
  
  # 查看启动状态
  jps
  ```

* web端（浏览器）查看 Job History

  http://hp-node1:19888

## 3.7、配置日志聚集

​	概念：应用运行（任务）完成以后，将程序（任务）运行日志信息上传到HDFS系统上。

​	作用：方便的查看到程序（任务）运行详情，方便开发调试。

​	注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryServer。

* 修改配置文件：yarn-site.xml

  ```shell
  vim $HADOOP_HOME/etc/hadoop/yarn-site.xml
  ```

  ```xml
  <!-- 添加以下内容 -->
      <!-- 开启日志聚集功能 -->
      <property>
          <name>yarn.log-aggregation-enable</name>
          <value>true</value>
      </property>
      <!-- 设置日志聚集服务器地址 -->
      <property>  
          <name>yarn.log.server.url</name>  
          <value>http://hp-node1:19888/jobhistory/logs</value>
      </property>
      <!-- 设置日志保留时间为7天 -->
      <property>
          <name>yarn.log-aggregation.retain-seconds</name>
          <value>604800</value>
      </property>
  ```

* 配置文件分发到其它节点

  ```shell
  xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml
  ```

* 关闭NodeManager 、ResourceManager和HistoryServer

  ```shell
  stop-dfs.sh
  stop-yarn.sh
  mapred --daemon stop historyserver
  ```

* 启动NodeManager 、ResourceManager和HistoryServer

  ```shell
  start-dfs.sh
  start-yarn.sh
  mapred --daemon start historyserver
  ```

* 测试

  ```shell
  # 运行之前需要把输入文件上传至hdfs输入路径中
  hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output
  ```

  > 注意：输入和输出路径是hdfs的；输出路径必须是不存在的。

* 查看

  ![image-20220806225140212](https://revenge-img.oss-cn-guangzhou.aliyuncs.com/img/image-20220806225140212.png)

  ![image-20220806225211414](https://revenge-img.oss-cn-guangzhou.aliyuncs.com/img/image-20220806225211414.png)

# 4、常用命令

* HDFS

  ```shell
  # HDFS整体启动和关闭
  start-dfs.sh
  stop-dfs.sh
  
  # HDFS各组件启动和关闭
  hdfs --daemon start/stop namenode/datanode/secondarynamenode
  ```

  > 整体启动和关闭需要配置ssh，不然只有当前执行命令的节点有效，集群其它节点无效。

* YARN

  ```shell
  # YARN整体启动和关闭
  start-yarn.sh
  stop-yarn.sh
  
  # YARN各组件启动和关闭
  yarn --daemon start/stop  resourcemanager/nodemanager
  ```

* 编写常用工具脚本

  ```shell
  # 启动集群和停止集群脚本
  vim /home/hp/bin/hp
  ```

  ```shell
  #!/bin/bash
  
  if [ $# -lt 1 ]
  then
      echo "No Args Input..."
      exit ;
  fi
  
  case $1 in
  "start")
          echo " =================== start hadoop ==================="
  
          echo " --------------- start hdfs ---------------"
          ssh hp-node1 "$HADOOP_HOME/sbin/start-dfs.sh"
          echo " --------------- start yarn ---------------"
          ssh hp-node2 "$HADOOP_HOME/sbin/start-yarn.sh"
          echo " --------------- start historyserver ---------------"
          ssh hp-node1 "$HADOOP_HOME/bin/mapred --daemon start historyserver"
  ;;
  "stop")
          echo " =================== stop hadoop ==================="
  
          echo " --------------- stop historyserver ---------------"
          ssh hp-node1 "$HADOOP_HOME/bin/mapred --daemon stop historyserver"
          echo " --------------- stop yarn ---------------"
          ssh hp-node2 "$HADOOP_HOME/sbin/stop-yarn.sh"
          echo " --------------- stop hdfs ---------------"
          ssh hp-node1 "$HADOOP_HOME/sbin/stop-dfs.sh"
  ;;
  *)
      echo "Input Args Error..."
  ;;
  esac
  ```

  ```shell
  # 添加执行权限
  chmod +x /home/hp/bin/hp
  # 分发到其它节点
  xsync /home/hp/bin/hp
  ```

  ```shell
  # 查看进程脚本
  vim /home/hp/bin/jpsall
  ```

  ```shell
  #!/bin/bash
  
  for host in hp-node1 hp-node2 hp-node3
  do
          echo =============== $host ===============
          ssh $host jps 
  done
  ```

  ```shell
  # 添加执行权限
  chmod +x /home/hp/bin/jpsall
  # 分发到其它节点
  xsync /home/hp/bin/jpsall
  ```

# 5、常用端口号和时间同步

## 5.1、常用端口号说明

| 端口名称                  | Hadoop2.x  | Hadoop3.x        |
| ------------------------- | ---------- | ---------------- |
| NameNode内部通信端口      | 8020、9000 | 8020、9000、9820 |
| NameNode HTTP UI          | 50070      | 9870             |
| MapReduce查看执行任务端口 | 8088       | 8088             |
| 历史服务器通信端口        | 19888      | 19888            |

> NameNode内部通信端口一般选择使用的是8020

## 5.2、时间同步

### 5.2.1、说明

* 作用：在集群节点服务器无法连接到公网的情况下保证集群时间一致，防止集群产生时间偏差，导致各种问题的出现，如：任务时间不同步。
* 使用集群中的其中一个节点作为时间节点服务器，其它节点与时间节点进行定时的时间同步，生存环境下同步的周期根据业务对时间的准确程度来决定。

### 5.2.2、配置

1. 安装ntpd（如果未安装的情况下）

   ```shell
   # 能够访问外网
   yum -y install ntp
   
   # 无法访问外网
   # 在能够访问外网的机器上下载离线包，下载完成之后上传至集群各个节点
   http://mirrors.163.com/centos/7/os/x86_64/Packages/ntp-4.2.6p5-29.el7.centos.2.x86_64.rpm
   # 离线安装
   rpm -ivh ntp-4.2.6p5-29.el7.centos.2.x86_64.rpm --nodeps --force
   ```

2. 查看时间节点ntpd服务的状态并设置为开机自启动

   ```shell
   # 查看状态ntpd
   sudo systemctl status ntpd
   # 启动ntpd
   sudo systemctl start ntpd
   # 设置ntpd为开机自启动
   sudo systemctl enable ntpd
   ```

3. 修改时间节点的配置文件：/etc/ntp.conf

   ```shell
   sudo vim /etc/ntp.conf
   
   # 在restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap下面添加以下内容
   restrict 192.168.88.0 mask 255.255.255.0 nomodify notrap
   ```

   > 授权192.168.88.0-192.168.88.255网段上的所有节点可以从这台节点上查询和同步时间。

   ```shell
   # 将配置文件中以下内容注释掉
   server 0.centos.pool.ntp.org iburst
   server 1.centos.pool.ntp.org iburst
   server 2.centos.pool.ntp.org iburst
   server 3.centos.pool.ntp.org iburst
   # 如下
   #server 0.centos.pool.ntp.org iburst
   #server 1.centos.pool.ntp.org iburst
   #server 2.centos.pool.ntp.org iburst
   #server 3.centos.pool.ntp.org iburst
   ```

   ```shell
   # 添加以下内容
   server 127.127.1.0
   fudge 127.127.1.0 stratum 10
   ```

   > 当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步

4. 修改时间节点的配置文件：/etc/sysconfig/ntpd

   ```shell
   sudo vim /etc/sysconfig/ntpd
   
   # 添加以下内容
   SYNC_HWCLOCK=yes
   ```

5. 重启时间节点的ntpd服务

   ```shell
   sudo systemctl restart ntpd
   ```

6. 停止其它节点的ntp服务和自启动（无法ntp没有安装可忽略）

   ```shell
   sudo systemctl stop ntpd
   sudo systemctl disable ntpd
   ```

7. 在其它时间上创建定时同步

   ```shell
   sudo crontab -e
   # 添加以下内容
   */1 * * * * /usr/sbin/ntpdate hp-node1
   ```

   > 当前方便测试设置的同步周期为一分钟，生存环境下同步的周期根据业务对时间的准确程度来决定。
   >
   > hp-node1是时间节点服务器。

8. 简单测试

   ```shell
   # 在时间节点服务器上修改时间
   sudo date -s "2021-9-11 11:11:11"
   
   # 一分钟后在其它节点上查看时间
   sudo date
   ```

# 6、常见错误及解决方案

* 防火墙没关闭或没有启动YARN

  INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032

* 主机名称配置错误

* IP地址配置错误

* ssh配置错误或未配置

* 启动集群用户不统一，如root用户部分组件，hp用户启动其它组件

* 配置文件修改错误

* 无法识别主机名称

  ```
  java.net.UnknownHostException: hadoop102: hadoop102
          at java.net.InetAddress.getLocalHost(InetAddress.java:1475)
          at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:146)
          at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
          at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
          at java.security.AccessController.doPrivileged(Native Method)
  at javax.security.auth.Subject.doAs(Subject.java:415)
  ```

  > 解决方案：修改/etc/hosts文件，把各个节点的ip地址和主机名添加进去。
  >
  > 注意：主机名不要使用hadoop、hadoop000等特殊名称。

* DataNode和NameNode进程同时只能工作一个

  原因分析：NameNode在format初始化（格式化）之后会生成clusterId（集群id），DateNode初始化启动之后也会生成与NameNode一样的clusterId，如果此时再次格式化，会再生成新的clusterId，与未删除的DataNode的clusterId不一致就会导致集群无法通信和工作。

  解决方案：在格式化之前，先删除DataNode节点中的信息，默认在/tmp目录下，如果已自定义配置则需要到配置的目录下进行删除。各个节点都删除完成之后再进行重新格式化。

  ![image-20220807003117318](https://revenge-img.oss-cn-guangzhou.aliyuncs.com/img/image-20220807003117318.png)

* 执行命令不生效，请手动敲，不要复制粘贴。

* jps发现进程已经不存在，但是重新启动集群，提示进程已经开启。

  原因分析：Linux的根目录下/tmp目录中存在启动的进程临时文件。

  解决方案：删除掉相关的进程临时文件，再重新启动集群。

* jps命令不生效，无法使用

  原因分析：hadoop、java 环境变量未配置、配置错误、未刷新环境变量

  解决方案：重新配置环境变量，然后刷新环境变量即可，具体操作步骤请参考前面的章节。

* 8088端口无法连接

  原因分析：防火墙未开放此端口或防火墙未关闭，/etc/hosts文件存在问题

  解决方案：防火墙开放端口或关闭防火墙，修改/etc/hosts文件，修改如下

  ```shell
  # 注释掉以下内容
  
  #127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
  #::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
  #::1 hp-node1
  ```



